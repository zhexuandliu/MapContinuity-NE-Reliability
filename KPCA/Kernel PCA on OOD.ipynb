{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded.\n",
      "Feature dimension = 50\n",
      "\n",
      "Running linear PCA...\n",
      "Linear PCA finished.\n",
      "explained variance ratio = 0.950000\n",
      "reduction dimension    q = 10\n",
      "s_accuml at q-1 = 0.944795\n",
      "s_accuml at q   = 0.953910\n",
      "s_accuml at q+1 = 0.959074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import time\n",
    "# import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# -------- fix random seed \n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "class Logger(object):\n",
    "    def __init__(self, filename='default.log', stream=sys.stdout):\n",
    "        self.terminal = stream\n",
    "        self.log = open(filename, 'a')\n",
    "    \n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "\n",
    "    def flush(self):\n",
    "        pass\n",
    "\n",
    "import metrics\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "train_In_size = 1000\n",
    "train_OoD_size = 0\n",
    "\n",
    "exp_var_ratio = 0.95\n",
    "import pandas as pd\n",
    "\n",
    "train_id = pd.read_csv(\"./train.csv\")\n",
    "test_id = pd.read_csv(\"./test.csv\")\n",
    "ood_id = pd.read_csv(\"./ood.csv\")\n",
    "ood_train_id = pd.read_csv(\"./ood_train.csv\")\n",
    "\n",
    "cache_name = os.path.join('./', \"CIFAR10_ResNet18_ce_pretrain_features_test.npy\")\n",
    "CIFAR10_test = np.load(cache_name, allow_pickle=True)\n",
    "cache_name = os.path.join('./', \"CIFAR10_ResNet18_ce_pretrain_features_DTD.npy\")\n",
    "DTD = np.load(cache_name, allow_pickle=True)\n",
    "\n",
    "train = CIFAR10_test[train_id.T.to_numpy()[0]-1]\n",
    "\n",
    "shuffled_train = np.random.permutation(train)\n",
    "train = shuffled_train[:train_In_size]\n",
    "\n",
    "test = CIFAR10_test[test_id.T.to_numpy()[0]-1]\n",
    "ood = DTD[ood_id.T.to_numpy()[0]-1] #ood_id.T.to_numpy()[0]-1\n",
    "\n",
    "ood_train = DTD[ood_train_id.T.to_numpy()[0]-1]\n",
    "shuffled_ood_train = np.random.permutation(ood_train)\n",
    "ood_train = shuffled_ood_train[:train_OoD_size]\n",
    "\n",
    "# train = np.vstack((train, ood_train))\n",
    "train = np.vstack((test, ood))\n",
    "\n",
    "# PCA step\n",
    "pca = PCA(n_components=50)\n",
    "train = pca.fit_transform(train)  # Fit & transform train\n",
    "test = pca.transform(test) \n",
    "ood = pca.transform(ood) \n",
    "\n",
    "\n",
    "feat_log = train\n",
    "feat_log = feat_log.astype(np.float32)\n",
    "\n",
    "feat_log_val = test\n",
    "feat_log_val = feat_log_val.astype(np.float32)\n",
    "\n",
    "ood_feat_log_all = {}\n",
    "ood_feat_log = ood\n",
    "ood_feat_log = ood_feat_log.astype(np.float32)\n",
    "ood_feat_log_all['DTD'] = ood_feat_log\n",
    "print(\"Features loaded.\")\n",
    "print(\"Feature dimension = %d\"%feat_log.shape[1])\n",
    "\n",
    "# -------- such an l2 normalization indicates a feature mapping w.r.t. a cosine kernel\n",
    "normalizer = lambda x: x / (np.linalg.norm(x, ord=2, axis=-1, keepdims=True) + 1e-10)\n",
    "prepos_feat = lambda x: np.ascontiguousarray(normalizer(x))\n",
    "\n",
    "ftrain = prepos_feat(feat_log)\n",
    "ftest = prepos_feat(feat_log_val)\n",
    "food_all = {}\n",
    "food_all['DTD'] = prepos_feat(ood_feat_log_all['DTD'])\n",
    "\n",
    "###### missing code for CoRP\n",
    "\n",
    "# -------- centralize the mapped features\n",
    "mu = ftrain.mean(axis=0)\n",
    "ftrain = ftrain - mu\n",
    "ftest = ftest - mu\n",
    "for ood_dataset, food in food_all.items():\n",
    "    food_all[ood_dataset] = food - mu\n",
    "\n",
    "# -------- linear PCA\n",
    "print()\n",
    "print(\"Running linear PCA...\")\n",
    "K = ftrain.T.dot(ftrain)\n",
    "u_full, s, _ = np.linalg.svd(K)\n",
    "# ---- the reduction dimension q is\n",
    "# ---- selected according to the explained variance ratio\n",
    "q, s_accuml = -1, np.zeros(ftrain.shape[1])\n",
    "for i in range(ftrain.shape[1]):\n",
    "    s_accuml[i] = sum(s[:i]) / sum(s)\n",
    "    if i > 0 and q < 0:\n",
    "        if s_accuml[i-1] < exp_var_ratio and s_accuml[i] >= exp_var_ratio:\n",
    "            q = i\n",
    "print(\"Linear PCA finished.\")\n",
    "print(\"explained variance ratio = %f\"%exp_var_ratio)\n",
    "print(\"reduction dimension    q = %d\"%q)\n",
    "print(\"s_accuml at q-1 = %f\"%s_accuml[q-1])\n",
    "print(\"s_accuml at q   = %f\"%s_accuml[q])\n",
    "print(\"s_accuml at q+1 = %f\"%s_accuml[q+1])\n",
    "\n",
    "# -------- reconstruction error for OoD detection\n",
    "u_q = u_full[:,:q]\n",
    "\n",
    "reconstruct_in = u_q.dot(u_q.T).dot(ftrain.T).T\n",
    "scores_in_train = - np.linalg.norm(ftrain-reconstruct_in, ord=2, axis=1)\n",
    "\n",
    "\n",
    "reconstruct_in = u_q.dot(u_q.T).dot(ftest.T).T\n",
    "scores_in = - np.linalg.norm(ftest-reconstruct_in, ord=2, axis=1)\n",
    "\n",
    "all_results = []\n",
    "for ood_dataset, food in food_all.items():\n",
    "    reconstruct_ood = u_q.dot(u_q.T).dot(food.T).T \n",
    "    scores_ood = - np.linalg.norm(food-reconstruct_ood, ord=2, axis=1)\n",
    "print()\n",
    "\n",
    "np.save(\"./KPCA_CoP_In.npy\", -scores_in)\n",
    "np.save(\"./KPCA_CoP_OOD.npy\", -scores_ood)\n",
    "\n",
    "# print(metrics.cal_metric(scores_in, scores_ood))\n",
    "\n",
    "# print()\n",
    "# print(\"The program ends...\")\n",
    "# print(\"-------- -------- --------\")\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FPR': 0.913, 'AUROC': 0.5767335, 'DTERR': 0.33166666666666667, 'AUIN': 0.7318662660869695, 'AUOUT': 0.3906969677431318}\n",
      "\n",
      "The program ends...\n",
      "-------- -------- --------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.cal_metric(scores_in, scores_ood))\n",
    "\n",
    "print()\n",
    "print(\"The program ends...\")\n",
    "print(\"-------- -------- --------\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded.\n",
      "Feature dimension = 512\n",
      "\n",
      "Running linear PCA...\n",
      "Linear PCA finished.\n",
      "explained variance ratio = 0.950000\n",
      "reduction dimension    q = 10\n",
      "s_accuml at q-1 = 0.941782\n",
      "s_accuml at q   = 0.953404\n",
      "s_accuml at q+1 = 0.957051\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# No training samples\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "# -------- fix random seed \n",
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "class Logger(object):\n",
    "    def __init__(self, filename='default.log', stream=sys.stdout):\n",
    "        self.terminal = stream\n",
    "        self.log = open(filename, 'a')\n",
    "    \n",
    "    def write(self, message):\n",
    "        self.terminal.write(message)\n",
    "        self.log.write(message)\n",
    "\n",
    "    def flush(self):\n",
    "        pass\n",
    "\n",
    "import metrics\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "train_In_size = 1000\n",
    "train_OoD_size = 0\n",
    "\n",
    "exp_var_ratio = 0.95\n",
    "import pandas as pd\n",
    "\n",
    "train_id = pd.read_csv(\"./train.csv\")\n",
    "test_id = pd.read_csv(\"./test.csv\")\n",
    "ood_id = pd.read_csv(\"./ood.csv\")\n",
    "ood_train_id = pd.read_csv(\"./ood_train.csv\")\n",
    "\n",
    "cache_name = os.path.join('./', \"CIFAR10_ResNet18_ce_pretrain_features_test.npy\")\n",
    "CIFAR10_test = np.load(cache_name, allow_pickle=True)\n",
    "cache_name = os.path.join('./', \"CIFAR10_ResNet18_ce_pretrain_features_DTD.npy\")\n",
    "DTD = np.load(cache_name, allow_pickle=True)\n",
    "\n",
    "train = CIFAR10_test[train_id.T.to_numpy()[0]-1]\n",
    "\n",
    "shuffled_train = np.random.permutation(train)\n",
    "train = shuffled_train[:train_In_size]\n",
    "\n",
    "test = CIFAR10_test[test_id.T.to_numpy()[0]-1]\n",
    "ood = DTD[ood_id.T.to_numpy()[0]-1] #ood_id.T.to_numpy()[0]-1\n",
    "\n",
    "ood_train = DTD[ood_train_id.T.to_numpy()[0]-1]\n",
    "shuffled_ood_train = np.random.permutation(ood_train)\n",
    "ood_train = shuffled_ood_train[:train_OoD_size]\n",
    "\n",
    "# train = np.vstack((train, ood_train))\n",
    "train = np.vstack((test, ood))\n",
    "\n",
    "feat_log = train\n",
    "feat_log = feat_log.astype(np.float32)\n",
    "\n",
    "feat_log_val = test\n",
    "feat_log_val = feat_log_val.astype(np.float32)\n",
    "\n",
    "ood_feat_log_all = {}\n",
    "ood_feat_log = ood\n",
    "ood_feat_log = ood_feat_log.astype(np.float32)\n",
    "ood_feat_log_all['DTD'] = ood_feat_log\n",
    "print(\"Features loaded.\")\n",
    "print(\"Feature dimension = %d\"%feat_log.shape[1])\n",
    "\n",
    "# -------- such an l2 normalization indicates a feature mapping w.r.t. a cosine kernel\n",
    "normalizer = lambda x: x / (np.linalg.norm(x, ord=2, axis=-1, keepdims=True) + 1e-10)\n",
    "prepos_feat = lambda x: np.ascontiguousarray(normalizer(x))\n",
    "\n",
    "ftrain = prepos_feat(feat_log)\n",
    "ftest = prepos_feat(feat_log_val)\n",
    "food_all = {}\n",
    "food_all['DTD'] = prepos_feat(ood_feat_log_all['DTD'])\n",
    "\n",
    "###### missing code for CoRP\n",
    "\n",
    "# -------- centralize the mapped features\n",
    "mu = ftrain.mean(axis=0)\n",
    "ftrain = ftrain - mu\n",
    "ftest = ftest - mu\n",
    "for ood_dataset, food in food_all.items():\n",
    "    food_all[ood_dataset] = food - mu\n",
    "\n",
    "# -------- linear PCA\n",
    "print()\n",
    "print(\"Running linear PCA...\")\n",
    "K = ftrain.T.dot(ftrain)\n",
    "u_full, s, _ = np.linalg.svd(K)\n",
    "# ---- the reduction dimension q is\n",
    "# ---- selected according to the explained variance ratio\n",
    "q, s_accuml = -1, np.zeros(ftrain.shape[1])\n",
    "for i in range(ftrain.shape[1]):\n",
    "    s_accuml[i] = sum(s[:i]) / sum(s)\n",
    "    if i > 0 and q < 0:\n",
    "        if s_accuml[i-1] < exp_var_ratio and s_accuml[i] >= exp_var_ratio:\n",
    "            q = i\n",
    "print(\"Linear PCA finished.\")\n",
    "print(\"explained variance ratio = %f\"%exp_var_ratio)\n",
    "print(\"reduction dimension    q = %d\"%q)\n",
    "print(\"s_accuml at q-1 = %f\"%s_accuml[q-1])\n",
    "print(\"s_accuml at q   = %f\"%s_accuml[q])\n",
    "print(\"s_accuml at q+1 = %f\"%s_accuml[q+1])\n",
    "\n",
    "# -------- reconstruction error for OoD detection\n",
    "u_q = u_full[:,:q]\n",
    "\n",
    "reconstruct_in = u_q.dot(u_q.T).dot(ftrain.T).T\n",
    "scores_in_train = - np.linalg.norm(ftrain-reconstruct_in, ord=2, axis=1)\n",
    "\n",
    "\n",
    "reconstruct_in = u_q.dot(u_q.T).dot(ftest.T).T\n",
    "scores_in = np.linalg.norm(ftest-reconstruct_in, ord=2, axis=1)\n",
    "\n",
    "all_results = []\n",
    "for ood_dataset, food in food_all.items():\n",
    "    reconstruct_ood = u_q.dot(u_q.T).dot(food.T).T \n",
    "    scores_ood = np.linalg.norm(food-reconstruct_ood, ord=2, axis=1)\n",
    "print()\n",
    "\n",
    "np.save(\"./KPCA_CoP_In.npy\", scores_in)\n",
    "np.save(\"./KPCA_CoP_OOD.npy\", scores_ood)\n",
    "\n",
    "# print(metrics.cal_metric(scores_in, scores_ood))\n",
    "\n",
    "# print()\n",
    "# print(\"The program ends...\")\n",
    "# print(\"-------- -------- --------\")\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FPR': 0.974, 'AUROC': 0.38311775, 'DTERR': 0.3333333333333333, 'AUIN': 0.5809770880420106, 'AUOUT': 0.27326118403340655}\n",
      "\n",
      "The program ends...\n",
      "-------- -------- --------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.cal_metric(- scores_in, - scores_ood))\n",
    "\n",
    "print()\n",
    "print(\"The program ends...\")\n",
    "print(\"-------- -------- --------\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13983703"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_in.mean()\n",
    "scores_ood.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamicviz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19 (default, Mar 20 2024, 15:27:52) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "306daca2d47815e35fde12aa46a4c2c0fa8aa9683398403f4add97944824ad1e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
